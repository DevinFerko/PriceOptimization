{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07e88fc2",
   "metadata": {},
   "source": [
    "### Price Optimization Machine Learning Model\n",
    "\n",
    "##### Objective\n",
    "We want to leverage a machine learning model to help us set optimal prices, the aim would be to increase revenue and/or margin while keeping in mind market conditions and customer trust.\n",
    "\n",
    "##### Why Now?\n",
    "I believe we are now well-positioned to design a price optimization model. We have complete access to all our current and historical Brightpearl data, including the pricing information we need.\n",
    "\n",
    "##### Expected Benefits\n",
    "- Revenue Uplift: with optimized pricing we can expect improved revenue performance per product\n",
    "- Margin Protection: An optimized model could help us avoid underpricing\n",
    "- Insights: Clear understanding of demand elasticity by product & segment\n",
    "\n",
    "##### Scope\n",
    "TBC\n",
    "\n",
    "##### Data Needed\n",
    "\n",
    "- Historical prices & sales (SKU × date/time × channel)\n",
    "- Product costs\n",
    "- Inventory & stockouts\n",
    "- Promotions & discounts\n",
    "- Competitor prices ????? Is this achieveable for us\n",
    "- External demand drivers (seasonality, events)\n",
    "\n",
    "##### Resources\n",
    "\n",
    "- Tools: Data warehouse (Perceptium), Python ML stack, Tableau BI dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de55d00f",
   "metadata": {},
   "source": [
    "### Breakdown of Data from Tables\n",
    "\n",
    "##### Historical prices & sales (SKU × date/time × channel) / Product costs\n",
    "Order Table:\n",
    "- ord_id - Order ID\n",
    "- ord_invoicetaxDate - Tax Date\n",
    "- ord_channelId - Channel ID\n",
    "- ord_orderTypeCode - Type code (used to filter, example: PC or SC is a refund????? Please confirm)\n",
    "\n",
    "Orderline Table:\n",
    "- orl_ord_id - Order ID (Number for overall order)\n",
    "- orl_id - OrderLine ID (Number for orderline, used to show individual lines inside of an order)\n",
    "- orl_productSku - product SKU\n",
    "- orl_productId - Product ID\n",
    "- orl_nominalCode - For filtering (Not needed as a column)\n",
    "- orl_itemCostValue - Cost (cost price for single unit of product)\n",
    "- orl_quantity - Quantity (number of items purchased)\n",
    "- orl_productPriceValue - Price (price of the product at the time the order is placed)\n",
    "- DO NOT USE - orl_discountPercentage - discount percent on row (not dependable) \n",
    "\n",
    "\n",
    "** 02/09/2025 - To test and train Model we are going to use potentially 5 to 10 top selling products, this will make it easier to source competitor pricing for the time being\n",
    "Products:\n",
    "\n",
    "\n",
    "Potential products to add:\n",
    "- Elba Charcoal Wall Hung Basin Drawer Vanity 600mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b667e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports Libraries - Remove unneeded \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import warnings\n",
    "import pyodbc\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose  \n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d49ef3f",
   "metadata": {},
   "source": [
    "##### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1af54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load datasets - Original Dataset use sql below for full model\n",
    "#orders = pd.read_csv('Order.csv')\n",
    "\n",
    "# --- Step 1: Read the credentials from the text file ---\n",
    "credentials = {}\n",
    "try:\n",
    "    with open('credentials.txt', 'r') as file:\n",
    "        for line in file:\n",
    "            # Remove leading/trailing whitespace and split the line at the first '='\n",
    "            key, value = line.strip().split('=', 1)\n",
    "            credentials[key.strip()] = value.strip()\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: The 'credentials.txt' file was not found.\")\n",
    "    exit() # or handle the error in another way\n",
    "\n",
    "# Assign credentials to variables\n",
    "server_name = credentials.get('server')\n",
    "database_name = credentials.get('database')\n",
    "username = credentials.get('username')\n",
    "password = credentials.get('password')\n",
    "driver = '{ODBC Driver 17 for SQL Server}'\n",
    "\n",
    "# Check for missing credentials\n",
    "if not all([server_name, database_name, username, password]):\n",
    "    raise ValueError(\"One or more credentials are missing from the file.\")\n",
    "\n",
    "# --- Step 2: Establish the connection ---\n",
    "try:\n",
    "    conn_string = (\n",
    "        f'DRIVER={driver};'\n",
    "        f'SERVER={server_name};'\n",
    "        f'DATABASE={database_name};'\n",
    "        f'UID={username};'\n",
    "        f'PWD={password};'\n",
    "    )\n",
    "    conn = pyodbc.connect(conn_string)\n",
    "    print(\"Connection to Azure SQL Database successful!\")\n",
    "\n",
    "except pyodbc.Error as ex:\n",
    "    print(f\"Error connecting to the database: {ex.args[0]}\")\n",
    "    conn = None\n",
    "\n",
    "# --- Step 3: Fetch merged data and load into a single DataFrame ---\n",
    "\n",
    "#points to sql file\n",
    "sql_path = Path(\"C:/Users/Devin Ferko/Desktop/Codes/Machine Learning Projects/Price Optimization/HistoricalPricesSales.sql\")\n",
    "\n",
    "with open(sql_path, 'r', encoding='utf-8') as file:\n",
    "    sql_query = file.read()\n",
    "    print(\"SQL query loaded from file.\")\n",
    "\n",
    "if conn:\n",
    "    try:\n",
    "        # Reads SQL query from file\n",
    "        merged_query = sql_query\n",
    "        \n",
    "        # Load the joined data directly into a single DataFrame\n",
    "        orders = pd.read_sql(merged_query, conn)\n",
    "        print(f\"Successfully loaded {len(orders)} rows from the merged query.\")\n",
    "        #print(\"\\nMerged DataFrame Head:\")\n",
    "        #print(orders.head())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while fetching data: {e}\")\n",
    "\n",
    "    finally:\n",
    "        conn.close()\n",
    "        print(\"Database connection closed.\")\n",
    "else:\n",
    "    print(\"Cannot proceed with data fetching. Database connection failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f00fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = orders.rename(columns={\"Product SKU\": \"SKU\"})\n",
    "#Info\n",
    "orders.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06eb0f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Null values per columns\n",
    "orders.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e261bf16",
   "metadata": {},
   "source": [
    "### Promotion Data\n",
    "\n",
    "We have a couple of CSV's with some promotional data that would be benefical to apply to this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870bfdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summer Sale 2025 - 25th of June to 27th of August\n",
    "summerSale25 = pd.read_csv(\"C:/Users/Devin Ferko/Desktop/Codes/Machine Learning Projects/Price Optimization/CSVs/Summer Sale 2025 - Prepped.csv\")\n",
    "\n",
    "#Uncomment the below if needed\n",
    "#summerSale25.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292ea1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spring Sale 2025 - March 5th to April 7th\n",
    "springSale25 = pd.read_csv(\"C:/Users/Devin Ferko/Desktop/Codes/Machine Learning Projects/Price Optimization/CSVs/Spring Sale 2025 - prepped.csv\")\n",
    "\n",
    "#Uncomment the below if needed\n",
    "#springSale25.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b105dfa",
   "metadata": {},
   "source": [
    "### Indicate if sale was present and apply discount percentages accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bfb60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Sale Boolean Column and the discount percentage applied\n",
    "\n",
    "# --- SUMMER SALE 2025 ---\n",
    "# Define date windows\n",
    "sum_start_date = pd.to_datetime('2025-06-25')\n",
    "sum_end_date = pd.to_datetime('2025-08-27')\n",
    "\n",
    "#Ensure clean dtypes - types for SKU are string and no trailing space\n",
    "orders[\"SKU\"] = orders[\"SKU\"].astype(str).str.strip()\n",
    "summerSale25[\"SKU\"] = summerSale25[\"SKU\"].astype(str).str.strip()\n",
    "\n",
    "#Add summer sale 2025 column\n",
    "orders[\"Summer_Sale\"] = (\n",
    "    orders[\"Tax Date\"].between(sum_start_date, sum_end_date) #True if date falls in between\n",
    "    & orders[\"SKU\"].isin(summerSale25[\"SKU\"]) #True if SKU matches\n",
    ").astype(\"int8\") # converts to boolean - t/f or 1/0\n",
    "\n",
    "#Bring in discount columns from the sale sheet\n",
    "#Keep only the columns we need from the sale table\n",
    "discount_cols = [\"% off list TW\", \"% off list DR\", \"% off list OR\"]\n",
    "orders = orders.merge(\n",
    "    summerSale25[[\"SKU\"] + discount_cols],\n",
    "    on=\"SKU\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "\n",
    "# Map Channel Id -> the corresponding discount column.\n",
    "channel_discount_map = {\n",
    "    \"2\": \"% off list TW\",\n",
    "    \"7\": \"% off list DR\",\n",
    "    \"8\": \"% off list OR\"\n",
    "}\n",
    "\n",
    "channel_key = orders[\"Channel Id\"].astype(str).str.strip() # Ensure Channel Id's are strings\n",
    "chosen_col = channel_key.map(channel_discount_map)  # per-row column name to use\n",
    "\n",
    "# Vectorized pick of the right discount per row\n",
    "disc_df = orders[discount_cols] #seperates discount values to seperate df\n",
    "col_indexer = pd.Index(discount_cols).get_indexer(chosen_col) # converts column names in chosen_col into numeric indices so we can index the DataFrame efficiently.\n",
    "row_indexer = np.arange(len(orders)) #array of row numbers [0, 1, 2, ..., n-1]\n",
    "\n",
    "result = np.full(len(orders), np.nan, dtype=float) #empty array to hold discount values\n",
    "in_window = orders[\"Tax Date\"].between(sum_start_date, sum_end_date) #True if in window\n",
    "valid_choice = col_indexer >= 0 #True if valid discount column exists for channel\n",
    "mask = in_window & valid_choice #only select discount for orders in window and with valid channel\n",
    "\n",
    "# Pull the values only where in window and with a valid channel/discount\n",
    "result[mask] = disc_df.to_numpy()[row_indexer[mask], col_indexer[mask]]\n",
    "orders[\"sumsale25_discount_percent\"] = result\n",
    "\n",
    "#If you prefer 0 instead of NaN when not applicable, uncomment:\n",
    "orders[\"sumsale25_discount_percent\"] = orders[\"sumsale25_discount_percent\"].fillna(0)\n",
    "\n",
    "#Drops unwanted columns\n",
    "orders = orders.drop(['% off list TW', '% off list DR', '% off list OR'], axis=1)\n",
    "\n",
    "# --- SPRING SALE 2025 ---\n",
    "# Define date windows\n",
    "spr_start_date = pd.to_datetime('2025-03-05')\n",
    "spr_end_date = pd.to_datetime('2025-04-07')\n",
    "\n",
    "#Ensure clean dtypes - types for SKU are string and no trailing space\n",
    "orders[\"SKU\"] = orders[\"SKU\"].astype(str).str.strip()\n",
    "springSale25[\"SKU\"] = springSale25[\"SKU\"].astype(str).str.strip()\n",
    "\n",
    "#Add summer sale 2025 column\n",
    "orders[\"Spring_Sale\"] = (\n",
    "    orders[\"Tax Date\"].between(spr_start_date, spr_end_date) #True if date falls in between\n",
    "    & orders[\"SKU\"].isin(springSale25[\"SKU\"]) #True if SKU matches\n",
    ").astype(\"int8\") # converts to boolean - t/f or 1/0\n",
    "\n",
    "#Bring in discount columns from the sale sheet\n",
    "#Keep only the columns we need from the sale table\n",
    "discount_cols = [\"% off list TW\", \"% off list DR\", \"% off list OR\"]\n",
    "orders = orders.merge(\n",
    "    springSale25[[\"SKU\"] + discount_cols],\n",
    "    on=\"SKU\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "\n",
    "# Map Channel Id -> the corresponding discount column.\n",
    "channel_discount_map = {\n",
    "    \"2\": \"% off list TW\",\n",
    "    \"7\": \"% off list DR\",\n",
    "    \"8\": \"% off list OR\"\n",
    "}\n",
    "\n",
    "channel_key = orders[\"Channel Id\"].astype(str).str.strip() # Ensure Channel Id's are strings\n",
    "chosen_col = channel_key.map(channel_discount_map)  # per-row column name to use\n",
    "\n",
    "# Vectorized pick of the right discount per row\n",
    "disc_df = orders[discount_cols] #seperates discount values to seperate df\n",
    "col_indexer = pd.Index(discount_cols).get_indexer(chosen_col) # converts column names in chosen_col into numeric indices so we can index the DataFrame efficiently.\n",
    "row_indexer = np.arange(len(orders)) #array of row numbers [0, 1, 2, ..., n-1]\n",
    "\n",
    "result = np.full(len(orders), np.nan, dtype=float) #empty array to hold discount values\n",
    "in_window = orders[\"Tax Date\"].between(spr_start_date, spr_end_date) #True if in window\n",
    "valid_choice = col_indexer >= 0 #True if valid discount column exists for channel\n",
    "mask = in_window & valid_choice #only select discount for orders in window and with valid channel\n",
    "\n",
    "# Pull the values only where in window and with a valid channel/discount\n",
    "result[mask] = disc_df.to_numpy()[row_indexer[mask], col_indexer[mask]]\n",
    "orders[\"sprsale25_discount_percent\"] = result\n",
    "\n",
    "#If you prefer 0 instead of NaN when not applicable, uncomment:\n",
    "orders[\"sprsale25_discount_percent\"] = orders[\"sprsale25_discount_percent\"].fillna(0)\n",
    "\n",
    "#Drops unwanted columns\n",
    "orders = orders.drop(['% off list TW', '% off list DR', '% off list OR'], axis=1)\n",
    "\n",
    "# --- TAX MONTH AND SEASONS ---\n",
    "# Extract the month number from Tax Date\n",
    "orders[\"TaxMonth\"] = orders[\"Tax Date\"].dt.month\n",
    "\n",
    "# Flag if TaxMonth is in summer (June=6, July=7, August=8 for example)\n",
    "orders[\"Winter\"] = orders[\"TaxMonth\"].isin([12, 1, 2]).astype(int)\n",
    "orders[\"Spring\"] = orders[\"TaxMonth\"].isin([3, 4, 5]).astype(int)\n",
    "orders[\"Summer\"] = orders[\"TaxMonth\"].isin([6, 7, 8]).astype(int)\n",
    "orders[\"Fall\"] = orders[\"TaxMonth\"].isin([9, 10, 11]).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155586d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the below if needed\n",
    "#orders.info() \n",
    "#orders.to_csv('out.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51470d81",
   "metadata": {},
   "source": [
    "### Product Attributes - Akeneo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f1844b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads akeneo product attribute dataset\n",
    "prdAttr = pd.read_csv(\"C:/Users/Devin Ferko/Desktop/Codes/Machine Learning Projects/Price Optimization/CSVs/Akeneo Product Attributes - Sheet1.csv\")\n",
    "\n",
    "#Uncomment the below if needed\n",
    "#prdAttr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a7aba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge attribute data\n",
    "orders = orders.merge(prdAttr, on='SKU', how='left')\n",
    "\n",
    "#Uncomment the below if needed\n",
    "#orders.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2689192a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads akeneo product attribute dataset\n",
    "compPrice = pd.read_csv(\"C:/Users/Devin Ferko/Desktop/Codes/Machine Learning Projects/Price Optimization/CSVs/Competitor Pricing.csv\")\n",
    "\n",
    "compPrice.drop(['Product Name'], axis=1, inplace=True)\n",
    "#Uncomment the below if needed\n",
    "#compPrice.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b35850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge attribute data\n",
    "orders = orders.merge(compPrice, on='SKU', how='left')\n",
    "\n",
    "#Uncomment the below if needed\n",
    "orders.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55999307",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "\n",
    "This dataset works as a great base but we could benefit from:\n",
    "\n",
    "- Customer Data\n",
    "\n",
    "however until this is avaialble we will move on with the above dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79542cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following should be adapted as the dataset grows\n",
    "# This step is uded to drop epmty columns\n",
    "# this will cut down any 'noisy' data that may not be needed\n",
    "\n",
    "empty_cols = [col for col in orders.columns if orders[col].isnull().all()]\n",
    "orders = orders.drop(columns=empty_cols)\n",
    "\n",
    "# Handles type columns\n",
    "# Uncomment 'OR' attributes if they occur when dataset fully built out \n",
    "orders[\"Type\"] = np.where(\n",
    "    orders[\"Type DR\"] != \"\", orders[\"Type DR\"],\n",
    "    np.where(\n",
    "        orders[\"Type TW\"] != \"\", orders[\"Type TW\"],\n",
    "        #np.where(\n",
    "            #orders[\"Type OR\"] != \"\", orders[\"Type OR\"],\n",
    "            np.nan\n",
    "        )\n",
    "    )\n",
    "#)\n",
    "\n",
    "# Handles Brand columns\n",
    "# Uncomment 'OR' attributes if they occur when dataset fully built out \n",
    "orders[\"Brand\"] = np.where(\n",
    "    orders[\"Brand DR\"] != \"\", orders[\"Brand DR\"],\n",
    "    np.where(\n",
    "        orders[\"Brand TW\"] != \"\", orders[\"Brand TW\"],\n",
    "        #np.where(\n",
    "            #orders[\"Brand OR\"] != \"\", orders[\"Brand OR\"],\n",
    "            np.nan\n",
    "        )\n",
    "    )\n",
    "#)\n",
    "\n",
    "# Handles LaunchDate columns\n",
    "# Uncomment 'OR' attributes if they occur when dataset fully built out \n",
    "orders[\"LaunchDate\"] = np.where(\n",
    "    orders[\"LaunchDate DR\"] != \"\", orders[\"LaunchDate DR\"],\n",
    "    np.where(\n",
    "        orders[\"LaunchDate TW\"] != \"\", orders[\"LaunchDate TW\"],\n",
    "        #np.where(\n",
    "            #orders[\"LaunchDate OR\"] != \"\", orders[\"LaunchDate OR\"],\n",
    "            np.nan\n",
    "        )\n",
    "    )\n",
    "#)\n",
    "\n",
    "orders = orders.drop(columns=[\"Type DR\", \"Type TW\"]) #, \"Type OR\"])\n",
    "orders = orders.drop(columns=[\"Brand DR\", \"Brand TW\"]) #, \"Brand OR\"])\n",
    "orders = orders.drop(columns=[\"LaunchDate DR\", \"LaunchDate TW\"]) #, \"Brand OR\"])\n",
    "\n",
    "\n",
    "#Uncomment if needed\n",
    "orders.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ade01d",
   "metadata": {},
   "source": [
    "Based on the above we have low values for Launch Date, Brand, Type, and Orientation. We are going to drop these for the current dataset but the below should be commented-out once the dataset grows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acd8dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment out when needed\n",
    "# Based on the above we have low values for Launch Date, Brand, Type, and Orientation\n",
    "orders = orders.drop(columns=[\"LaunchDate\", \"Brand\", \"Type\", \"Orientation\"]) \n",
    "\n",
    "orders.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d564db38",
   "metadata": {},
   "source": [
    "### Next Steps will be Visualisations and further feature engineering:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c462f9c4",
   "metadata": {},
   "source": [
    "##### Visualizations\n",
    "\n",
    "- Price and Sales: Plot Price of Product against Quantity to see if there's a clear price elasticity. Do sales decrease as prices increase?\n",
    "\n",
    "- Time-based Trends: Examine Total or Quantity over time using Tax Date. This can reveal seasonality, which may affect pricing decisions. You already have Summer, Winter, etc., which is a great start.\n",
    "\n",
    "- Product Attributes: Compare prices (Price of Product) and sales (Quantity) across different product attributes like Family, Material, and Finish. This can help you understand which attributes are associated with higher or lower prices and sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727279ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price and Sales\n",
    "\n",
    "products = orders['SKU'].unique()\n",
    "print(f\"Number of unique products: {len(products)}\")\n",
    "\n",
    "for product in products:\n",
    "    subset = orders[orders['SKU'] == product]\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.scatter(subset['Price of Product'], subset['Quantity'], alpha=0.6)\n",
    "    plt.title(f'Price vs Quantity for Product SKU: {product}')\n",
    "    plt.xlabel('Price of Product')\n",
    "    plt.ylabel('Quantity Sold')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720dd980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasonality and Trends\n",
    "\n",
    "#products = orders['SKU'].unique()\n",
    "#print(f\"Number of unique products: {len(products)}\")\n",
    "\n",
    "for product in products:\n",
    "    subset = orders[orders['SKU'] == product]\n",
    "    daily_qty = subset.groupby('Tax Date')['Quantity'].sum()\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(daily_qty.index, daily_qty.values, alpha=0.6)\n",
    "    plt.title(f'Quantity by Tax Date for Product SKU: {product}')\n",
    "    plt.xlabel('Tax Date')\n",
    "    plt.ylabel('Quantity Sold')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3743b54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product Attributes\n",
    "\n",
    "# Columns names for easy reference\n",
    "price_cols = 'Price of Product'\n",
    "quantity_cols = 'Quantity'\n",
    "sku_cols = 'SKU'\n",
    "\n",
    "# Columns to exclude from attributes\n",
    "exclude_cols = ['Tax Date', 'Order ID', 'Net', 'Total', 'Type Code', 'Orderline ID', 'Product ID', 'Product Name', 'Product Value', 'Product Tax Value',\n",
    "                'Nominal Code', 'uuid', 'Comp Price 1 - Victoria Plumbing', 'Comp Price 2', 'Comp Price 3']\n",
    "\n",
    "# Aggregate by SKU\n",
    "sku_sales = orders.groupby(sku_cols).agg(\n",
    "    total_quantity=(quantity_cols, 'sum'),\n",
    "    avg_price=(price_cols, 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Plot SKU vs Quantity\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(sku_sales[sku_cols], sku_sales['total_quantity'], color='skyblue')\n",
    "plt.xlabel('Product SKU')\n",
    "plt.ylabel('Total Quantity Sold')\n",
    "plt.title('Quantity Sold by Product SKU')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot SKU vs Average Price\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(sku_sales[sku_cols], sku_sales['avg_price'], color='salmon')\n",
    "plt.xlabel('Product SKU')\n",
    "plt.ylabel('Average Price')\n",
    "plt.title('Average Price by Product SKU')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# for eacch attribute\n",
    "attribute_columns = [col for col in orders.columns if col not in [price_cols, quantity_cols, sku_cols] + exclude_cols]\n",
    "\n",
    "for attr in attribute_columns:\n",
    "    attr_sales = orders.groupby(attr).agg(\n",
    "        total_quantity=(quantity_cols, 'sum'),\n",
    "        avg_price=(price_cols, 'mean')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Plot Attribute vs Quantity\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(attr_sales[attr].astype(str), attr_sales['total_quantity'], color='lightgreen')\n",
    "    plt.xlabel(attr)\n",
    "    plt.ylabel('Total Quantity Sold')\n",
    "    plt.title(f'Quantity Sold by {attr}')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    # Uncomment when needed\n",
    "    #plt.show()\n",
    "\n",
    "    #plot Attribute vs Average Price\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(attr_sales[attr].astype(str), attr_sales['avg_price'], color='orange')\n",
    "    plt.xlabel(attr)\n",
    "    plt.ylabel('Average Price')\n",
    "    plt.title(f'Average Price by {attr}')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    # Uncomment when needed\n",
    "    #plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ce3fc7",
   "metadata": {},
   "source": [
    "##### Feature Engineering\n",
    "\n",
    "- Profitability/Margin: Calculate a Profit column by subtracting Cost of Product from Price of Product. This is a crucial target variable for optimization, as you might want to maximize profit, not just revenue.\n",
    "\n",
    "- Price Metrics: Create features that represent the relative price of a product. For example, a Price_vs_Competitors feature could be the average of Comp Price 1, Comp Price 2, and Comp Price 3 divided by your Price of Product. This tells the model how competitive your pricing is.\n",
    "\n",
    "- Categorical Encoding: Many machine learning models can't handle text data directly. Convert categorical columns like Family, Colour, Material, and Style into a numerical format. One-hot encoding is a common method for this, where each unique category becomes a new column with binary values (0 or 1). We will use pandas built in get_dummies\n",
    "\n",
    "- Sales Ratios: If you have historical data, you could engineer a Sales_per_product_per_week feature by aggregating historical sales data. This can help the model understand a product's baseline popularity.\n",
    "\n",
    "- Interaction Features: Combine existing features to create new ones. For example, Price of Product multiplied by Winter could tell the model if price has a different impact during the winter season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc0c5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addition of profitability column - Price of Product - Cost of Product\n",
    "orders['Margin'] = orders['Price of Product'] - orders['Cost of Product']\n",
    "orders['Margin'] = orders['Margin'].fillna(0)\n",
    "\n",
    "# Price versus competitor pricing\n",
    "orders['priceVsComps'] = (orders['Comp Price 1 - Victoria Plumbing']+ orders['Comp Price 2'] + orders['Comp Price 3']) / orders['Price of Product']\n",
    "#orders['priceVsComps'] = orders['avgPriceVsComp'].fillna(0)\n",
    "\n",
    "# Get dummies for one-hot encoding of categorical variables\n",
    "categorical_cols = ['Family', 'Colour', 'Finish', 'Finish Texture', 'Material', 'Style', 'Guarantee', 'Number Of Bowls',\n",
    "                    'Overflow', 'Shape', 'Sink Drainers', 'Sink Holes']\n",
    "\n",
    "# Assign one-hot encoded columns back to orders DataFrame - drop_first avoids dummy variable trap espically important for regression models (Comment out if needed  )\n",
    "orders = pd.get_dummies(orders, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Dataset Features - uncomment when needed\n",
    "#orders.head()\n",
    "orders.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
