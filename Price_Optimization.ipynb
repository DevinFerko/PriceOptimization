{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07e88fc2",
   "metadata": {},
   "source": [
    "### Price Optimization Machine Learning Model\n",
    "\n",
    "##### Objective\n",
    "We want to leverage a machine learning model to help us set optimal prices, the aim would be to increase revenue and/or margin while keeping in mind market conditions and customer trust.\n",
    "\n",
    "##### Why Now?\n",
    "I believe we are now well-positioned to design a price optimization model. We have complete access to all our current and historical Brightpearl data, including the pricing information we need.\n",
    "\n",
    "##### Expected Benefits\n",
    "- Revenue Uplift: with optimized pricing we can expect improved revenue performance per product\n",
    "- Margin Protection: An optimized model could help us avoid underpricing\n",
    "- Insights: Clear understanding of demand elasticity by product & segment\n",
    "\n",
    "##### Scope\n",
    "TBC\n",
    "\n",
    "##### Data Needed\n",
    "\n",
    "- Historical prices & sales (SKU × date/time × channel)\n",
    "- Product costs\n",
    "- Inventory & stockouts\n",
    "- Promotions & discounts\n",
    "- Competitor prices ????? Is this achieveable for us\n",
    "- External demand drivers (seasonality, events)\n",
    "\n",
    "##### Resources\n",
    "\n",
    "- Tools: Data warehouse (Perceptium), Python ML stack, Tableau BI dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de55d00f",
   "metadata": {},
   "source": [
    "### Breakdown of Data from Tables\n",
    "\n",
    "##### Historical prices & sales (SKU × date/time × channel) / Product costs\n",
    "Order Table:\n",
    "- ord_id - Order ID\n",
    "- ord_invoicetaxDate - Tax Date\n",
    "- ord_channelId - Channel ID\n",
    "- ord_orderTypeCode - Type code (used to filter, example: PC or SC is a refund????? Please confirm)\n",
    "\n",
    "Orderline Table:\n",
    "- orl_ord_id - Order ID (Number for overall order)\n",
    "- orl_id - OrderLine ID (Number for orderline, used to show individual lines inside of an order)\n",
    "- orl_productSku - product SKU\n",
    "- orl_productId - Product ID\n",
    "- orl_nominalCode - For filtering (Not needed as a column)\n",
    "- orl_itemCostValue - Cost (cost price for single unit of product)\n",
    "- orl_quantity - Quantity (number of items purchased)\n",
    "- orl_productPriceValue - Price (price of the product at the time the order is placed)\n",
    "- DO NOT USE - orl_discountPercentage - discount percent on row (not dependable) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b667e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports Libraries - Remove unneeded \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import warnings\n",
    "import pyodbc\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose  \n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d49ef3f",
   "metadata": {},
   "source": [
    "##### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1af54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load datasets - Original Dataset use sql below for full model\n",
    "#orders = pd.read_csv('Order.csv')\n",
    "\n",
    "# --- Step 1: Read the credentials from the text file ---\n",
    "credentials = {}\n",
    "try:\n",
    "    with open('credentials.txt', 'r') as file:\n",
    "        for line in file:\n",
    "            # Remove leading/trailing whitespace and split the line at the first '='\n",
    "            key, value = line.strip().split('=', 1)\n",
    "            credentials[key.strip()] = value.strip()\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: The 'credentials.txt' file was not found.\")\n",
    "    exit() # or handle the error in another way\n",
    "\n",
    "# Assign credentials to variables\n",
    "server_name = credentials.get('server')\n",
    "database_name = credentials.get('database')\n",
    "username = credentials.get('username')\n",
    "password = credentials.get('password')\n",
    "driver = '{ODBC Driver 17 for SQL Server}'\n",
    "\n",
    "# Check for missing credentials\n",
    "if not all([server_name, database_name, username, password]):\n",
    "    raise ValueError(\"One or more credentials are missing from the file.\")\n",
    "\n",
    "# --- Step 2: Establish the connection ---\n",
    "try:\n",
    "    conn_string = (\n",
    "        f'DRIVER={driver};'\n",
    "        f'SERVER={server_name};'\n",
    "        f'DATABASE={database_name};'\n",
    "        f'UID={username};'\n",
    "        f'PWD={password};'\n",
    "    )\n",
    "    conn = pyodbc.connect(conn_string)\n",
    "    print(\"Connection to Azure SQL Database successful!\")\n",
    "\n",
    "except pyodbc.Error as ex:\n",
    "    print(f\"Error connecting to the database: {ex.args[0]}\")\n",
    "    conn = None\n",
    "\n",
    "# --- Step 3: Fetch merged data and load into a single DataFrame ---\n",
    "if conn:\n",
    "    try:\n",
    "        # SQL query to join the two tables - Use top(10000) for initial start until model is ready for larger dataset (this effects speed)\n",
    "        # Note - WHERE o.ord_invoicetaxDate >= '2025-04-01' which shortens the reporting date for speed but on model complete increase data range\n",
    "        merged_query = \"\"\"\n",
    "        SELECT DISTINCT --TOP(10000)\n",
    "    o.ord_id AS [Order ID],\n",
    "    o.ord_invoicetaxDate AS [Tax Date],\n",
    "    o.ord_net AS [Net],\n",
    "    o.ord_total AS [Total],\n",
    "    o.ord_channelId AS [Channel Id],\n",
    "    ord_orderTypeCode AS [Type Code],\n",
    "    ol.orl_id AS [Orderline ID],\n",
    "    ol.orl_productId AS [Product Id],\n",
    "    ol.orl_productSku AS [Product SKU],\n",
    "    ol.orl_productName AS [Product Name],\n",
    "    ol.orl_quantity AS [Quantity],    \n",
    "    CASE \n",
    "        WHEN ol.orl_compositionBundleParent = 1 THEN op.bpar_orl_calcRowNetValue\n",
    "        WHEN ol.orl_compositionBundleChild = 1 THEN oc.bchd_orl_calcRowNetValue\n",
    "        ELSE ol.orl_rowNetValue\n",
    "    END AS [Product Value],\n",
    "    CASE \n",
    "        WHEN ol.orl_compositionBundleParent = 1 THEN op.bpar_orl_calcRowTaxValue\n",
    "        WHEN ol.orl_compositionBundleChild = 1 THEN oc.bchd_orl_calcRowTaxValue\n",
    "        ELSE ol.orl_rowTaxValue\n",
    "    END AS [Product Tax Value],\n",
    "    ol.orl_productPriceValue AS [Price of Product],\n",
    "    CASE \n",
    "        WHEN ol.orl_compositionBundleParent = 1 THEN op.bpar_orl_itemCostValue\n",
    "        WHEN ol.orl_compositionBundleChild = 1 THEN oc.bchd_orl_itemCostValue\n",
    "        ELSE ol.orl_itemCostValue\n",
    "    END AS [Cost of Product],\n",
    "    ol.orl_nominalCode AS [Nominal Code]\n",
    "FROM dbo.tblOrder AS o\n",
    "LEFT JOIN dbo.tblOrderLine AS ol ON o.ord_id = ol.orl_ord_id\n",
    "LEFT JOIN Perceptium.tblOrderLineParentView AS op ON ol.orl_id = op.bpar_orl_id\n",
    "LEFT JOIN Perceptium.tblOrderLineChildView AS oc ON ol.orl_id = oc.bchd_orl_id\n",
    "WHERE o.ord_invoicetaxDate >= '2025-04-01' \n",
    "        \"\"\"\n",
    "        \n",
    "        # Load the joined data directly into a single DataFrame\n",
    "        orders = pd.read_sql(merged_query, conn)\n",
    "        print(f\"Successfully loaded {len(orders)} rows from the merged query.\")\n",
    "        #print(\"\\nMerged DataFrame Head:\")\n",
    "        #print(orders.head())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while fetching data: {e}\")\n",
    "\n",
    "    finally:\n",
    "        conn.close()\n",
    "        print(\"Database connection closed.\")\n",
    "else:\n",
    "    print(\"Cannot proceed with data fetching. Database connection failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f00fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = orders.rename(columns={\"Product SKU\": \"SKU\"})\n",
    "#Info\n",
    "orders.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06eb0f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Null values per columns\n",
    "\n",
    "orders.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e261bf16",
   "metadata": {},
   "source": [
    "### Promotion Data\n",
    "\n",
    "We have a couple of CSV's with some promotional data that would be benefical to apply to this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870bfdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summer Sale 2025 - 25th of June to 27th of August\n",
    "summerSale25 = pd.read_csv(\"C:/Users/Devin Ferko/Desktop/Codes/Machine Learning Projects/Price Optimization/Summer Sale 2025 - Prepped.csv\")\n",
    "summerSale25.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292ea1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spring Sale 2025 - March 5th to April 7th\n",
    "springSale25 = pd.read_csv(\"C:/Users/Devin Ferko/Desktop/Codes/Machine Learning Projects/Price Optimization/Spring Sale 2025 - prepped.csv\")\n",
    "springSale25.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b105dfa",
   "metadata": {},
   "source": [
    "### Indicate if sale was present and apply discount percentages accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bfb60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Sale Boolean Column and the discount percentage applied\n",
    "\n",
    "# --- SUMMER SALE 2025 ---\n",
    "# Define date windows\n",
    "sum_start_date = pd.to_datetime('2025-06-25')\n",
    "sum_end_date = pd.to_datetime('2025-08-27')\n",
    "\n",
    "#Ensure clean dtypes - types for SKU are string and no trailing space\n",
    "orders[\"SKU\"] = orders[\"SKU\"].astype(str).str.strip()\n",
    "summerSale25[\"SKU\"] = summerSale25[\"SKU\"].astype(str).str.strip()\n",
    "\n",
    "#Add summer sale 2025 column\n",
    "orders[\"Summer_Sale\"] = (\n",
    "    orders[\"Tax Date\"].between(sum_start_date, sum_end_date) #True if date falls in between\n",
    "    & orders[\"SKU\"].isin(summerSale25[\"SKU\"]) #True if SKU matches\n",
    ").astype(\"int8\") # converts to boolean - t/f or 1/0\n",
    "\n",
    "#Bring in discount columns from the sale sheet\n",
    "#Keep only the columns we need from the sale table\n",
    "discount_cols = [\"% off list TW\", \"% off list DR\", \"% off list OR\"]\n",
    "orders = orders.merge(\n",
    "    summerSale25[[\"SKU\"] + discount_cols],\n",
    "    on=\"SKU\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "\n",
    "# Map Channel Id -> the corresponding discount column.\n",
    "channel_discount_map = {\n",
    "    \"2\": \"% off list TW\",\n",
    "    \"7\": \"% off list DR\",\n",
    "    \"8\": \"% off list OR\"\n",
    "}\n",
    "\n",
    "channel_key = orders[\"Channel Id\"].astype(str).str.strip() # Ensure Channel Id's are strings\n",
    "chosen_col = channel_key.map(channel_discount_map)  # per-row column name to use\n",
    "\n",
    "# Vectorized pick of the right discount per row\n",
    "disc_df = orders[discount_cols] #seperates discount values to seperate df\n",
    "col_indexer = pd.Index(discount_cols).get_indexer(chosen_col) # converts column names in chosen_col into numeric indices so we can index the DataFrame efficiently.\n",
    "row_indexer = np.arange(len(orders)) #array of row numbers [0, 1, 2, ..., n-1]\n",
    "\n",
    "result = np.full(len(orders), np.nan, dtype=float) #empty array to hold discount values\n",
    "in_window = orders[\"Tax Date\"].between(sum_start_date, sum_end_date) #True if in window\n",
    "valid_choice = col_indexer >= 0 #True if valid discount column exists for channel\n",
    "mask = in_window & valid_choice #only select discount for orders in window and with valid channel\n",
    "\n",
    "# Pull the values only where in window and with a valid channel/discount\n",
    "result[mask] = disc_df.to_numpy()[row_indexer[mask], col_indexer[mask]]\n",
    "orders[\"sumsale25_discount_percent\"] = result\n",
    "\n",
    "#If you prefer 0 instead of NaN when not applicable, uncomment:\n",
    "orders[\"sumsale25_discount_percent\"] = orders[\"sumsale25_discount_percent\"].fillna(0)\n",
    "\n",
    "#Drops unwanted columns\n",
    "orders = orders.drop(['% off list TW', '% off list DR', '% off list OR'], axis=1)\n",
    "\n",
    "# --- SPRING SALE 2025 ---\n",
    "# Define date windows\n",
    "spr_start_date = pd.to_datetime('2025-03-05')\n",
    "spr_end_date = pd.to_datetime('2025-04-07')\n",
    "\n",
    "#Ensure clean dtypes - types for SKU are string and no trailing space\n",
    "orders[\"SKU\"] = orders[\"SKU\"].astype(str).str.strip()\n",
    "springSale25[\"SKU\"] = springSale25[\"SKU\"].astype(str).str.strip()\n",
    "\n",
    "#Add summer sale 2025 column\n",
    "orders[\"Spring_Sale\"] = (\n",
    "    orders[\"Tax Date\"].between(spr_start_date, spr_end_date) #True if date falls in between\n",
    "    & orders[\"SKU\"].isin(springSale25[\"SKU\"]) #True if SKU matches\n",
    ").astype(\"int8\") # converts to boolean - t/f or 1/0\n",
    "\n",
    "#Bring in discount columns from the sale sheet\n",
    "#Keep only the columns we need from the sale table\n",
    "discount_cols = [\"% off list TW\", \"% off list DR\", \"% off list OR\"]\n",
    "orders = orders.merge(\n",
    "    springSale25[[\"SKU\"] + discount_cols],\n",
    "    on=\"SKU\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "\n",
    "# Map Channel Id -> the corresponding discount column.\n",
    "channel_discount_map = {\n",
    "    \"2\": \"% off list TW\",\n",
    "    \"7\": \"% off list DR\",\n",
    "    \"8\": \"% off list OR\"\n",
    "}\n",
    "\n",
    "channel_key = orders[\"Channel Id\"].astype(str).str.strip() # Ensure Channel Id's are strings\n",
    "chosen_col = channel_key.map(channel_discount_map)  # per-row column name to use\n",
    "\n",
    "# Vectorized pick of the right discount per row\n",
    "disc_df = orders[discount_cols] #seperates discount values to seperate df\n",
    "col_indexer = pd.Index(discount_cols).get_indexer(chosen_col) # converts column names in chosen_col into numeric indices so we can index the DataFrame efficiently.\n",
    "row_indexer = np.arange(len(orders)) #array of row numbers [0, 1, 2, ..., n-1]\n",
    "\n",
    "result = np.full(len(orders), np.nan, dtype=float) #empty array to hold discount values\n",
    "in_window = orders[\"Tax Date\"].between(spr_start_date, spr_end_date) #True if in window\n",
    "valid_choice = col_indexer >= 0 #True if valid discount column exists for channel\n",
    "mask = in_window & valid_choice #only select discount for orders in window and with valid channel\n",
    "\n",
    "# Pull the values only where in window and with a valid channel/discount\n",
    "result[mask] = disc_df.to_numpy()[row_indexer[mask], col_indexer[mask]]\n",
    "orders[\"sprsale25_discount_percent\"] = result\n",
    "\n",
    "#If you prefer 0 instead of NaN when not applicable, uncomment:\n",
    "orders[\"sprsale25_discount_percent\"] = orders[\"sprsale25_discount_percent\"].fillna(0)\n",
    "\n",
    "#Drops unwanted columns\n",
    "orders = orders.drop(['% off list TW', '% off list DR', '% off list OR'], axis=1)\n",
    "\n",
    "# --- TAX MONTH AND SEASONS ---\n",
    "# Extract the month number from Tax Date\n",
    "orders[\"TaxMonth\"] = orders[\"Tax Date\"].dt.month\n",
    "\n",
    "# Flag if TaxMonth is in summer (June=6, July=7, August=8 for example)\n",
    "orders[\"Winter\"] = orders[\"TaxMonth\"].isin([12, 1, 2]).astype(int)\n",
    "orders[\"Spring\"] = orders[\"TaxMonth\"].isin([3, 4, 5]).astype(int)\n",
    "orders[\"Summer\"] = orders[\"TaxMonth\"].isin([6, 7, 8]).astype(int)\n",
    "orders[\"Fall\"] = orders[\"TaxMonth\"].isin([9, 10, 11]).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155586d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the below if needed\n",
    "#orders.info() \n",
    "#orders.to_csv('out.csv') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
